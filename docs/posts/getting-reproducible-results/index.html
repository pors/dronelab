<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Mark Pors">
<meta name="dcterms.date" content="2025-05-25">
<meta name="keywords" content="pytorch reproducibility, fastai reproducible training, dataloader seeding, torch deterministic, machine learning experiments, pytorch random seed, cudnn deterministic, reproducible deep learning">
<meta name="description" content="Why your Fast.ai or PyTorch experiments keep giving different results even when you think you’ve seeded everything properly. Spoiler: it’s not just about random seeds - DataLoaders have hidden state that screws things up. Here’s how to actually fix it.">

<title>Interlude: Getting reproducible training results with Fast.ai + PyTorch – dronelab.dev</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-985aa47af68dae11cd4d235c71fb941e.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-a368816def9a8950b8d88926fee9d1b8.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-J790G06FED"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-J790G06FED', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Getting reproducible training results with Fast.ai + PyTorch">
<meta property="og:description" content="Why your Fast.ai or PyTorch experiments keep giving different results even when you think you’ve seeded everything properly. Spoiler: it’s not just about random seeds - DataLoaders have hidden state that screws things up. Here’s how to actually fix it.">
<meta property="og:image" content="https://dronelab.dev/posts/getting-reproducible-results/reproducible.png">
<meta property="og:site_name" content="dronelab.dev">
<meta property="og:image:alt" content="DroneLab - Coding Autonomous Drones in Baby Steps.">
<meta property="og:image:height" content="720">
<meta property="og:image:width" content="1280">
<meta name="twitter:title" content="Getting reproducible training results with Fast.ai + PyTorch">
<meta name="twitter:description" content="Why your Fast.ai or PyTorch experiments keep giving different results even when you think you’ve seeded everything properly. Spoiler: it’s not just about random seeds - DataLoaders have hidden state that screws things up. Here’s how to actually fix it.">
<meta name="twitter:image" content="https://dronelab.dev/posts/getting-reproducible-results/reproducible.png">
<meta name="twitter:image:alt" content="Getting reproducible training results with Fast.ai + PyTorch">
<meta name="twitter:creator" content="@pors">
<meta name="twitter:site" content="@pors">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image-height" content="720">
<meta name="twitter:image-width" content="1280">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">dronelab.dev</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/pors"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/pors"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="3">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#what-have-i-tried" id="toc-what-have-i-tried" class="nav-link active" data-scroll-target="#what-have-i-tried">What have I tried?</a></li>
  <li><a href="#rtfm" id="toc-rtfm" class="nav-link" data-scroll-target="#rtfm">RTFM</a>
  <ul>
  <li><a href="#fast.ai-docs" id="toc-fast.ai-docs" class="nav-link" data-scroll-target="#fast.ai-docs">Fast.ai docs</a></li>
  <li><a href="#pytorch-docs" id="toc-pytorch-docs" class="nav-link" data-scroll-target="#pytorch-docs">PyTorch docs</a>
  <ul class="collapse">
  <li><a href="#controlling-sources-of-randomness" id="toc-controlling-sources-of-randomness" class="nav-link" data-scroll-target="#controlling-sources-of-randomness">1. Controlling sources of randomness</a></li>
  <li><a href="#avoiding-nondeterministic-algorithms" id="toc-avoiding-nondeterministic-algorithms" class="nav-link" data-scroll-target="#avoiding-nondeterministic-algorithms">2. Avoiding nondeterministic algorithms</a></li>
  <li><a href="#dataloader" id="toc-dataloader" class="nav-link" data-scroll-target="#dataloader">3. DataLoader</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#lets-get-some-help-hello-claude" id="toc-lets-get-some-help-hello-claude" class="nav-link" data-scroll-target="#lets-get-some-help-hello-claude">Let’s get some help (hello Claude)</a></li>
  <li><a href="#hhhhh" id="toc-hhhhh" class="nav-link" data-scroll-target="#hhhhh">^H^H^H^H^H</a>
  <ul>
  <li><a href="#observations" id="toc-observations" class="nav-link" data-scroll-target="#observations">Observations</a>
  <ul class="collapse">
  <li><a href="#num_workers" id="toc-num_workers" class="nav-link" data-scroll-target="#num_workers">num_workers:</a></li>
  <li><a href="#use_deterministic_algorithms" id="toc-use_deterministic_algorithms" class="nav-link" data-scroll-target="#use_deterministic_algorithms">use_deterministic_algorithms:</a></li>
  <li><a href="#set_seed" id="toc-set_seed" class="nav-link" data-scroll-target="#set_seed">set_seed:</a></li>
  <li><a href="#cudnn.deterministic" id="toc-cudnn.deterministic" class="nav-link" data-scroll-target="#cudnn.deterministic">cudnn.deterministic:</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#whats-next" id="toc-whats-next" class="nav-link" data-scroll-target="#whats-next">What’s next</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><h1 class="title display-7">Interlude: Getting reproducible training results with Fast.ai + PyTorch</h1></header>

<header id="title-block-header">

<p class="author">Mark Pors</p>

<p class="date">2025-05-25</p>
</header>


<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
TL;DR
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Getting reproducible PyTorch/Fast.ai training results requires more than just seeding random number generators. Reproducibility is affected by three factors:</p>
<ol type="1">
<li>seeding RNGs,</li>
<li>using deterministic algorithms, and</li>
<li>recreating an identical starting state.</li>
</ol>
<p><strong>Key insights</strong>:</p>
<ul>
<li>DataLoaders maintain internal state that persists between training runs. You must recreate DataLoaders before each training run, not just reseed.</li>
<li>DataLoader workers need to be seeded before each run.</li>
</ul>
<p><strong>Minimal setup for reproducibility:</strong></p>
<ul>
<li>Set <code>torch.backends.cudnn.deterministic = True</code></li>
<li>Recreate DataLoaders between runs</li>
<li>Basic RNG seeding <em>and</em> DataLoader worker seeding</li>
</ul>
</div>
</div>
</div>
<p>While training an <a href="../fly-drone-with-image-classification/">image classifier</a>, I became a bit annoyed by the fact that subsequent runs have different results, even though I didn’t change anything.</p>
<p>How can we conduct experiments if we don’t know whether the one parameter I modified caused the change, or if something else was responsible, under the hood?</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Why this matters
</div>
</div>
<div class="callout-body-container callout-body">
<p>This cost me days of debugging. When you’re tuning hyperparameters or comparing model architectures, you need to know whether that 2% accuracy improvement is real or just random variance. Without reproducibility, you’re flying blind.</p>
</div>
</div>
<p><a href="#conclusion">Jump to Conclusion</a></p>
<section id="what-have-i-tried" class="level2">
<h2 class="anchored" data-anchor-id="what-have-i-tried">What have I tried?</h2>
<p>When I did my experiments, I used this at the start of my notebooks:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> seed_everything(seed):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    random.seed(seed)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    os.environ[<span class="st">'PYTHONHASHSEED'</span>] <span class="op">=</span> <span class="bu">str</span>(seed)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    np.random.seed(seed)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    torch.manual_seed(seed)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    torch.cuda.manual_seed_all(seed)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    torch.cuda.manual_seed(seed)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    torch.backends.cudnn.deterministic <span class="op">=</span> <span class="va">True</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>seed_everything(<span class="dv">42</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>And in the <code>DataBlock</code>, I provided a seed for the splitter like:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>    splitter<span class="op">=</span>RandomSplitter(valid_pct<span class="op">=</span><span class="fl">0.2</span>, seed<span class="op">=</span><span class="dv">42</span>),</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>I picked up these snippets in the Fast.ai course, but I don’t really know what each of these statements does in detail. I understand the general idea: ensure that when a random number is generated, it starts from the same seed, so that the random number is consistent each time. Like:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Without seed:"</span>, random.randint(<span class="dv">1</span>, <span class="dv">100</span>), random.randint(<span class="dv">1</span>, <span class="dv">100</span>), random.randint(<span class="dv">1</span>, <span class="dv">100</span>))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">42</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"With seed 42:"</span>, random.randint(<span class="dv">1</span>, <span class="dv">100</span>), random.randint(<span class="dv">1</span>, <span class="dv">100</span>), random.randint(<span class="dv">1</span>, <span class="dv">100</span>))</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">42</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"With seed 42 again:"</span>, random.randint(<span class="dv">1</span>, <span class="dv">100</span>), random.randint(<span class="dv">1</span>, <span class="dv">100</span>), random.randint(<span class="dv">1</span>, <span class="dv">100</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre class="text"><code>Without seed: 15 60 38
With seed 42: 81 14 3
With seed 42 again: 81 14 3</code></pre>
</div>
<p>Unfortunately, it is not that simple, proven by the fact that it didn’t work for me. Here is an experiment that shows that loss numbers are not reproducible despite seeding “everything”: <a href="https://colab.research.google.com/drive/1BDCNvpn7MFiTE0k-q21A-YKoYAiGypug?usp=sharing" target="_blank">Getting reproducible results with Fast.ai / PyTorch - Attempt #1</a>.</p>
<p>Perhaps a good time to read the documentation.</p>
</section>
<section id="rtfm" class="level2">
<h2 class="anchored" data-anchor-id="rtfm">RTFM</h2>
<section id="fast.ai-docs" class="level3">
<h3 class="anchored" data-anchor-id="fast.ai-docs">Fast.ai docs</h3>
<p>There is currently no section to be found in the Fast.ai docs covering reproducibility, but there was in version one (deprecated): <a href="https://fastai1.fast.ai/dev/test.html#getting-reproducible-results" target="_blank">Getting reproducible results</a>:</p>
<blockquote class="blockquote">
<p>In some situations you may want to remove randomness for your tests. To get identical reproducible results set, you’ll need to set num_workers=1 (or 0) in your DataLoader/DataBunch, and depending on whether you are using torch’s random functions, or python’s (numpy) or both:</p>
</blockquote>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># python RNG</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>random.seed(seed)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># pytorch RNGs</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(seed)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>torch.backends.cudnn.deterministic <span class="op">=</span> <span class="va">True</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co"># numpy RNG</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>np.random.seed(seed)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The Python and numpy parts speak for themselves. I will dive into the PyTorch statements in a moment.</p>
<p>If we compare this code with what I did in my first attempt, the only thing that is new is <code>num_workers=1</code> for dataloaders.</p>
<p>I tried that, and nope: still not reproducible.</p>
<p>The current docs don’t have a section like the one above, but there is a function <a href="https://docs.fast.ai/torch_core.html#set_seed" target="_blank">set_seed</a> (only available in Fast.ai). Let’s have a look at the <a href="https://github.com/fastai/fastai/blob/main/fastai/torch_core.py#L161" target="_blank">source code</a>:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> set_seed(s, reproducible<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"Set random seed for `random`, `torch`, and `numpy` (where available)"</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>: torch.manual_seed(s)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">NameError</span>: <span class="cf">pass</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>: torch.cuda.manual_seed_all(s)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">NameError</span>: <span class="cf">pass</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>: np.random.seed(s<span class="op">%</span>(<span class="dv">2</span><span class="op">**</span><span class="dv">32</span><span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">NameError</span>: <span class="cf">pass</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    random.seed(s)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> reproducible:</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        torch.backends.cudnn.deterministic <span class="op">=</span> <span class="va">True</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        torch.backends.cudnn.benchmark <span class="op">=</span> <span class="va">False</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>So, mostly the same stuff, except: <code>torch.backends.cudnn.benchmark = False</code>. Which leads us to the PyTorch docs…</p>
</section>
<section id="pytorch-docs" class="level3">
<h3 class="anchored" data-anchor-id="pytorch-docs">PyTorch docs</h3>
<p>Luckily, there is a note about reproducibility in the PyTorch docs: <a href="https://docs.pytorch.org/docs/stable/notes/randomness.html" target="_blank">Reproducibility</a>.</p>
<p>There is a warning at the top of the document that I will repeat here.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Deterministic operations are often slower than nondeterministic operations, so single-run performance may decrease for your model. However, determinism may save time in development by facilitating experimentation, debugging, and regression testing.</p>
</div>
</div>
<p>So it might be worth trying to make everything deterministic during our early experiments (with a smaller dataset and smaller base model), and when we are confident we are on the right track, we switch to nondeterministic.</p>
<p>Sounds great! But first we have to get the deterministic part working in the first place…</p>
<p>The PyTorch doc consists of three sections. Let’s go through them one by one.</p>
<section id="controlling-sources-of-randomness" class="level4">
<h4 class="anchored" data-anchor-id="controlling-sources-of-randomness">1. Controlling sources of randomness</h4>
<p>Apart from reiterating the assignment of a fixed seed for Python, NumPy, and PyTorch, it also discusses the <code>cudnn.benchmark</code> feature we saw earlier. <code>cudnn</code> is a library built on top of CUDA that accelerates the training of neural networks. Apparently, it starts by trying out a couple of approaches (that’s the benchmarking), and picks the winner for the rest of the training. There is randomness involved in this benchmarking, so setting it to <code>False</code> should make the process deterministic.</p>
<p>What happened when I tried this?</p>
<p>-&gt; Still no reproducible results!</p>
</section>
<section id="avoiding-nondeterministic-algorithms" class="level4">
<h4 class="anchored" data-anchor-id="avoiding-nondeterministic-algorithms">2. Avoiding nondeterministic algorithms</h4>
<p>Now it gets interesting! PyTorch provides a method that might solve our problems: <a href="https://docs.pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html#torch.use_deterministic_algorithms" target="_blank">torch.use_deterministic_algorithms(True)</a>.</p>
<p>This statement instructs all other Torch code to use the deterministic variant of its algorithms, and if this is not possible, to throw an exception.</p>
<p>And that is exactly what I got, an exception:</p>
<div class="cell-output cell-output-stdout">
<pre class="text"><code>RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-12-25c053374517&gt; in &lt;cell line: 0&gt;()
      1 learn = vision_learner(dls, resnet18, metrics=error_rate)
----&gt; 2 learn.fine_tune(3)

21 frames
/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py in forward(self, input)
    123 
    124     def forward(self, input: Tensor) -&gt; Tensor:
--&gt; 125         return F.linear(input, self.weight, self.bias)
    126 
    127     def extra_repr(self) -&gt; str:

RuntimeError: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA &gt;= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility</code></pre>
</div>
<p>It didn’t happen in some exotic part of the library, but at the most elemental level that even I understand: <code>return F.linear(input, self.weight, self.bias)</code>.</p>
<p>The error message is super specific and helpful:</p>
<p><code class="wrap">Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA &gt;= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility</code></p>
<p>Let’s see what version of CUDA we are using on Colab:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(torch.version.cuda)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre class="text"><code>12.4</code></pre>
</div>
<p>Following the advice and setting this at the top of the notebook</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">'CUBLAS_WORKSPACE_CONFIG'</span>] <span class="op">=</span> <span class="st">':4096:8'</span>   <span class="co"># or ':16:8'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>got me over this hurdle!</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Just a “Restart session and run all” is not enough after introducing this environment var. You have to actually disconnect from the colab runtime, connect again, and run all.</p>
</div>
</div>
<p>We got a step further, but another error pops up, now in the backward pass:</p>
<div class="cell-output cell-output-stdout">
<pre class="text"><code>RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-11-af2d886d9870&gt; in &lt;cell line: 0&gt;()
      1 print(os.environ['CUBLAS_WORKSPACE_CONFIG'])
      2 learn = vision_learner(dls, resnet18, metrics=error_rate)
----&gt; 3 learn.fine_tune(3)

22 frames
/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py in _engine_run_backward(t_outputs, *args, **kwargs)
    821         unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)
    822     try:
--&gt; 823         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
    824             t_outputs, *args, **kwargs
    825         )  # Calls into the C++ engine to run the backward pass

RuntimeError: adaptive_max_pool2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True)'. You can turn off determinism just for this operation, or you can use the 'warn_only=True' option, if that's acceptable for your application. You can also file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation.</code></pre>
</div>
<p>Oh, oh, bad news. We have no other choice now to set the <code>warn_only</code> flag to <code>True</code> on the <code>use_deterministic_algorithms</code> call. This indeed allows the fine-tuning run to finish, but still not reproducible :(</p>
</section>
<section id="dataloader" class="level4">
<h4 class="anchored" data-anchor-id="dataloader">3. DataLoader</h4>
<p>Finally, the PyTorch doc about reproducibility mentions the possibility of seeding dataloader workers identically. As we previously used only one worker, I assume this won’t have any impact on our case. And guess what: it doesn’t <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>!</p>
<p>Here is the notebook where I did all the experiments as recommended in the docs: <a href="https://colab.research.google.com/drive/1b2F6J_-FhG37odYyrJPxBdjPtyTzJGkn?usp=sharing" target="_blank">Getting reproducible results with Fast.ai / PyTorch - Attempt #2</a>. BTW the Colab GPU was of type L4.</p>
<p>Speaking of GPUs: would we get reproducible results if we run it on a CPU? The answer is NO (I tried) <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>.</p>
</section>
</section>
</section>
<section id="lets-get-some-help-hello-claude" class="level2">
<h2 class="anchored" data-anchor-id="lets-get-some-help-hello-claude">Let’s get some help (hello Claude)</h2>
<p>The documentation didn’t really help. All the tricks to keep everything deterministic failed. It could be the backward pass, in which case we don’t have much hope of resolving it. But how do people train their models if you can’t do any experiments where just one meta-parameter changes?</p>
<p>Anyway, we are not giving up! Let’s ask our friend the LLM.</p>
<p>Claude speaks:</p>
<blockquote class="blockquote">
<p>When you create a DataLoader in PyTorch, it establishes its own internal random state that becomes decoupled from the global random seed. The DataLoader contains several stateful components that persist between training runs:</p>
<p>The DataLoader’s internal random number generator gets initialized when you first create it, and this generator maintains its own state independently of any subsequent global seed resets. Even though you call seed_everything(42) before each run, the DataLoader’s internal RNG has already advanced its state from the previous run and won’t reset back to its initial position.</p>
<p>The data shuffling mechanism also maintains state. Even with a fixed seed in your RandomSplitter, the underlying shuffling operations within the DataLoader can accumulate state changes that persist across runs, leading to subtle differences in the exact order that batches are presented to your model.</p>
</blockquote>
<p>Ah, of course, state is the key thing here! Random generators can start nicely with the same seed again, but if the state is not the same as it was before, that has no impact!</p>
<p>So let’s apply that wisdom by setting the seeds <em>and</em> recreate the <code>DataLoader</code> before starting a new training run…</p>
<p>Victory, we have reproducible results now! Have a look at this winning notebook: <a href="https://colab.research.google.com/drive/1yphkoDvcmb67JGXXCFK_dRN74VEY72lm?usp=sharing" target="_blank">Getting reproducible results with Fast.ai / PyTorch - Attempt #3</a>.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Even with the most conservative setup, like in this notebook, there can be small differences between runs. I noticed this when changing the GPU model from L4 to A100. This is acknowledged in the PyTorch documentation.</p>
</div>
</div>
<p>There is just one problem with it: it has become really slow.</p>
</section>
<section id="hhhhh" class="level2">
<h2 class="anchored" data-anchor-id="hhhhh">^H^H^H^H^H</h2>
<p>For you younger kids: ^H is the backspace character in Unix-type terminals. In other words, let’s delete some of the things we have done to increase reproducibility at the cost of performance.</p>
<section id="observations" class="level3">
<h3 class="anchored" data-anchor-id="observations">Observations</h3>
<section id="num_workers" class="level4">
<h4 class="anchored" data-anchor-id="num_workers">num_workers:</h4>
<p>Changing from <code>num_workers=0</code> to <code>num_workers=12</code> <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> maintains reproducibility, but only if the workers are seeded as follows (from the PyTorch docs):</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> seed_worker(worker_id):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    worker_seed <span class="op">=</span> torch.initial_seed() <span class="op">%</span> <span class="dv">2</span><span class="op">**</span><span class="dv">32</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    numpy.random.seed(worker_seed)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    random.seed(worker_seed)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> torch.Generator()</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>g.manual_seed(<span class="dv">42</span>)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>DataLoader(</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    train_dataset,</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    batch_size<span class="op">=</span>batch_size,</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    num_workers<span class="op">=</span>num_workers,</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    worker_init_fn<span class="op">=</span>seed_worker,</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    generator<span class="op">=</span>g,</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This also maintains reproducibility across sessions.</p>
<p>I’m very happy this works as it speeds up things significantly!</p>
</section>
<section id="use_deterministic_algorithms" class="level4">
<h4 class="anchored" data-anchor-id="use_deterministic_algorithms">use_deterministic_algorithms:</h4>
<p>Removing <code>torch.use_deterministic_algorithms(True)</code> also maintains reproducibility, both in the notebook and across sessions <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
</section>
<section id="set_seed" class="level4">
<h4 class="anchored" data-anchor-id="set_seed">set_seed:</h4>
<p>Setting the second parameter of <code>set_seed</code>, <code>reproducible</code> to <code>False</code> (which is the default) basically sets <code>torch.backends.cudnn.benchmark = False</code> in our case. This also maintains reproducibility, both in the notebook and across sessions.</p>
</section>
<section id="cudnn.deterministic" class="level4">
<h4 class="anchored" data-anchor-id="cudnn.deterministic">cudnn.deterministic:</h4>
<p>Setting <code>torch.backends.cudnn.deterministic = False</code> breaks reproducibility, so it is essential when running meaningful experiments. I hardly saw any performance degradation by setting this to <code>True</code>, but that might be different for other use cases.</p>
<p><strong>Key findings</strong>: as long as you seed every DataLoader worker and keep <code>torch.backends.cudnn.deterministic = True</code>, you can crank <code>num_workers</code> back up, drop <code>torch.use_deterministic_algorithms(True)</code>, and rely on the default <code>set_seed(..., reproducible=False)</code>: reproducibility still holds across notebook sessions while you recover full training speed.</p>
<p>The notebook that has applied the above, and is fast and reproducible, is here: <a href="https://colab.research.google.com/drive/1fOHcdEDja9OzmIBLkGqTiRf6gknVJGy-?usp=sharing" target="_blank">Getting reproducible results with Fast.ai / PyTorch - Attempt #4</a></p>
</section>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>These conclusions are probably not generic for all training pipelines and base models, but they probably are for convolutional networks like Resnet18. It might be different for transformer-based models, who knows. At least we know what knobs we can turn to get reproducible results.</p>
</div>
</div>
<p>Reproducible training comes down to three levers:</p>
<ol type="1">
<li>Seed every RNG – Python random, NumPy, and each DataLoader worker (worker_init_fn + torch.Generator).</li>
<li>Force deterministic kernels <code>torch.backends.cudnn.deterministic = True</code> (leave benchmarking off while you experiment).</li>
<li>Start from the same state: rebuild the DataLoader before each fresh run so its internal sampler is reset.</li>
</ol>
<p>If you are using Fast.ai, use the <a href="https://colab.research.google.com/drive/1fOHcdEDja9OzmIBLkGqTiRf6gknVJGy-?usp=sharing" target="_blank">Fast.ai notebook</a> as a reference for reproducible training.</p>
<p>In the end it comes down to:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># First run</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>seed_everything(<span class="dv">42</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> torch.Generator()</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>g.manual_seed(<span class="dv">42</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>torch.backends.cudnn.deterministic <span class="op">=</span> <span class="va">True</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> create_dataloaders(g)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> vision_learner(dls, resnet18, metrics<span class="op">=</span>error_rate)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>learn.fine_tune(<span class="dv">3</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Next run(s)</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>seed_everything(<span class="dv">42</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>g <span class="op">=</span> torch.Generator()</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>g.manual_seed(<span class="dv">42</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> create_dataloaders(g)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> vision_learner(dls, resnet18, metrics<span class="op">=</span>error_rate)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>learn.fine_tune(<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>If you prefer to just use PyTorch, use the <a href="https://colab.research.google.com/drive/1DB--1tnAOGdc5wgHNFc0KE5xhcJFRXgh?usp=sharing" target="_blank">PyTorch notebook</a> (Claude generated this based on the Fast.ai version) <a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>.</p>
<p>Once you move from experimentation to full-scale training, you can flip <code>torch.backends.cudnn.deterministic = False</code> to potentially regain speed. Just remember that it will sacrifice strict repeatability.</p>
</section>
<section id="whats-next" class="level2">
<h2 class="anchored" data-anchor-id="whats-next">What’s next</h2>
<p>Another interlude that got a bit out of hand. Time to go back to our <a href="../fly-drone-with-image-classification/">image classifier</a> and see if we can improve it. Read on…</p>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>As I found out later, it certainly does matter when using more than one worker, which is what you always want in order to have acceptable performance.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>With what I know now, this is because I didn’t recreate the dataloaders between runs. If we did that and used a CPU, the results would be reproducible.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>This is the default in my case; it is calculated as <code>min(16, os.cpu_count())</code>.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>This stays repeatable unless your model calls a layer that can’t guarantee identical results on the GPU; in that case, the numbers may shift a bit between runs, or PyTorch will throw a warning.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>I found a few excellent blog posts mainly focused on reproducibility with PyTorch: <a href="https://darinabal.medium.com/deep-learning-reproducible-results-using-pytorch-42034da5ad7">Reproducible Deep Learning Using PyTorch</a>, and <a href="https://medium.com/@heyamit10/pytorch-reproducibility-a-practical-guide-d6f573cba679">PyTorch Reproducibility: A Practical Guide</a>.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/dronelab\.dev");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>