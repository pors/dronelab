---
title: "Fly a drone with: Image classification - Part 2"
author: "Mark Pors"
date: "2025-05-22"
categories: [drone, code, tello, machine learning, image classification, fast.ai]
image: image-classification-lamps2.png
series: "Code, Fly & AI"
order: 8
draft: true
---

@@@ Remove draft: true and Write the header contents for SEO:
description
meta-description
keywords

::: {.callout-tip collapse="true"}
## TL;DR
@@@ Write a tight, high-signal TL;DR summarizing the key takeaways from this post. Focus on what the reader learns or does, not just what happens. Use bullet points, be clear, concise, and engaging. Reader might use this to decide to continue reading.

<div style="text-align: center;">
<strong>Series: <a href="/series/">Code, Fly & AI</a></strong>
</div>

<div style="display: flex; justify-content: space-between; margin-top: 0.5em;">
  <div>[← Previous: Fly a drone with: Image classification - Part 1](/posts/fly-drone-with-image-classification/)</div>
</div>

:::

## How we can improve the classifier

We left off with a ["lamp or no-lamp" image classifier](../fly-drone-with-image-classification/) that was pretty good with a less than 5% error rate. However, I had some doubts about over-fitting due to playing with the meta parameters (like the mini-batch size).

So the first thing to figure out is: are we over-fitting?

When I'm confident we are good, we can try:

* apply tricks from [chapter five](https://github.com/fastai/fastbook/blob/master/05_pet_breeds.ipynb){target="_blank"} in the fast.ai book
* collect more images to train on
* larger models

I think this is the right order to do things. We still keep the idea of a baseline model intact (before we move on to more data and larger models), secondly, lager models don't do well with a small dataset. Lots of model parameters allow memorization if the dataset is small.

## Are we over-fitting?








## Introducing a test dataset

A test dataset that the model has never seen before is a great way to determine if I played with the meta-parameters in my favour. 

But is this actually true? As soon as I use the test set to make decisions, I again play with a meta-parameter. There is even jargon for it: *Test set leakage*.

@@@ and create a test set!

@@@ other ideas: split out lamp closeups in its own class, use a better model, more data (see chatgpt suggestions https://chatgpt.com/c/682209c4-8378-8011-be8f-0769e8159e9e and https://chatgpt.com/c/6821fb1d-857c-8011-a3b2-cdd77e285a79 and https://chatgpt.com/c/6821f9f6-da74-8011-8bdd-b9eb2904500f).

@@@ test-set model run (from drone shots).

## Try it out on some drone images

@@@

## What's next?

@@@ next post: deploy on edge & cool demo. See a lamp => do something. Maybe sequences of images where the lamp comes into view and goes out of view by changing height, turning, coming closer, etc.


::: {.callout-note appearance="minimal"}
<div style="text-align: center;">
<strong>Series: <a href="/series/">Code, Fly & AI</a></strong>
</div>

<div style="display: flex; justify-content: space-between; margin-top: 0.5em;">
    <div>[← Previous: Fly a drone with: Image classification - Part 1](/posts/fly-drone-with-image-classification/)</div>
</div>
:::
